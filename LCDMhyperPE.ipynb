{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:57 bilby INFO    : Running bilby version: 0.3.6: (CLEAN) 97937d1 2019-02-11 21:15:16 -0600\n",
      "12:58 bilby WARNING : You do not have lalsuite installed currently. You will not be able to use some of the prebuilt functions.\n",
      "12:58 bilby WARNING : You do not have lalsuite installed currently. You will not be able to use some of the prebuilt functions.\n",
      "12:58 bilby WARNING : You do not have lalsuite installed currently. You will not be able to use some of the prebuilt functions.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "LCDMmockdata_fim_snr.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7e3b90a394b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mkk\u001b[0m      \u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m     \u001b[1;31m############### posterior resample number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;31m##################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m \u001b[0mpars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LCDMmockdata_fim_snr.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m dfpars=pd.DataFrame(pars, columns = ['mass_1', 'mass_2', 'a_1', 'a_2', 'tilt_1', 'tilt_2',\n\u001b[0;32m    103\u001b[0m                      \u001b[1;34m'phi_12'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'phi_jl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'luminosity_distance'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'theta_jn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'psi'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding)\u001b[0m\n\u001b[0;32m    924\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[0mfh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\numpy\\lib\\_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    616\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[0;32m    617\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: LCDMmockdata_fim_snr.txt not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import bilby\n",
    "from bilby.core.prior import Uniform\n",
    "from bilby.core.sampler import run_sampler\n",
    "from bilby.hyper.likelihood import HyperparameterLikelihood\n",
    "from scipy import interpolate\n",
    "import pandas as pd\n",
    "from scipy import integrate\n",
    "outdir='outdir'\n",
    "\n",
    "#defalut gaussian PDF replace BILBY for posterior, N(theta,sigma_theta)\n",
    "#parameter: mu=N(0,err_fisher)+mu_ture, sigma=err_fisher, prior\n",
    "#return: array( mu_posterior,evidence)\n",
    "class SimpleGaussianLikelihood1s(bilby.Likelihood):\n",
    "    def __init__(self, data1):\n",
    "        self.data1 = data1\n",
    "        self.parameters = {'mu1': None, 'sigma1': None}\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        mu1 = self.parameters['mu1']\n",
    "        sigma1 = self.parameters['sigma1']\n",
    "        res1 = self.data1 - mu1\n",
    "        return -0.5 * (np.sum((res1**2) / (sigma1**2)) +\n",
    "                       1* np.log(2 * np.pi * (sigma1**2)))\n",
    "class SimpleGaussianLikelihood2s(bilby.Likelihood):\n",
    "    def __init__(self, data2):\n",
    "        self.data2 = data2\n",
    "        self.parameters = {'mu2': None, 'sigma2': None}\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        mu2 = self.parameters['mu2']\n",
    "        sigma2 = self.parameters['sigma2']\n",
    "        res2 = self.data2 - mu2\n",
    "        return -0.5 * (np.sum((res2**2) / (sigma2**2)) +\n",
    "                       1* np.log(2 * np.pi * (sigma2**2))) \n",
    "class SimpleGaussianLikelihood3s(bilby.Likelihood):\n",
    "    def __init__(self, data3):\n",
    "        self.data3 = data3\n",
    "        self.parameters = {'mu3': None, 'sigma3': None}\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        mu3 = self.parameters['mu3']\n",
    "        sigma3 = self.parameters['sigma3']\n",
    "        res3 = self.data3 - mu3\n",
    "        return -0.5 * (np.sum((res3**2) / (sigma3**2)) +\n",
    "                       1* np.log(2 * np.pi * (sigma3**2)))\n",
    "#######################################################################\n",
    "zmax=9\n",
    "deltaz=0.1\n",
    "c_l=3*10**5\n",
    "def EZ(x,omm):\n",
    "    return 1/np.sqrt((omm*(1+x)**3+(1-omm)))\n",
    "def trapzez(H0,omm):\n",
    "    x=np.arange(0,zmax,deltaz)\n",
    "    s=np.zeros(len(x)+1)\n",
    "    for i in range(len(x)):\n",
    "        s[i]=np.trapz(EZ(x,omm)[0:i+1],x[0:i+1]) \n",
    "    return (s[:-1])*(1+x)*(c_l/H0)\n",
    "#interpolate redshift and DL contain HO omm\n",
    "def getz(DL,H0,omm):\n",
    "    x=np.arange(0,zmax,deltaz)\n",
    "    f=interpolate.interp1d(trapzez(H0,omm),x)\n",
    "    gez=f(DL)\n",
    "    return gez\n",
    "def PDL(DL,H0,omm):\n",
    "    z=getz(DL,H0,omm)\n",
    "    return (DL*DL)/((1+z)**3)\n",
    "######################################################\n",
    "#mmin is the min value for m1\n",
    "alpha=1.5\n",
    "mmax=40\n",
    "lamda=0.1\n",
    "mpp=35\n",
    "deltapp=1.0\n",
    "beta=-0.2\n",
    "mmin=8\n",
    "deltam=1.901\n",
    "def fm(m):\n",
    "    return deltam/(m)-(deltam/((m-deltam)))\n",
    "def Sm(m):\n",
    "    return 1/(np.exp(fm(m-4.901))+1)\n",
    "def ppow(m):\n",
    "    return (m**(-1*alpha))*Sm(m)\n",
    "def ppp(m):\n",
    "    return np.exp(-1*(m-mpp)**2/(2*deltapp*deltapp))*Sm(m)\n",
    "def Pm1(m):\n",
    "    return ((1-lamda)*ppow(m)+lamda*ppp(m))\n",
    "def Pm2(m2,m):\n",
    "    return ((m2/m)**beta)*Sm(m2)\n",
    "def normPm1(m):\n",
    "    ss=np.trapz(Pm1(np.arange(mmin,40.5,0.5)),np.arange(mmin,40.5,0.5))\n",
    "    return (Pm1(m)/ss)\n",
    "def normPm2(m2,m):\n",
    "    ss=np.trapz(Pm2(np.arange(mmin,40.5,0.5),40),np.arange(mmin,40.5,0.5))\n",
    "    return Pm2(m2,m)/ss\n",
    "##################################################################\n",
    "choiceN =200      ############### set injection events\n",
    "orlive  =800      ############### set the nlive nestle sample for posterior\n",
    "kk      =1000     ############### posterior resample number \n",
    "##################################################################\n",
    "#load generate mock data, set sample size form the mock data\n",
    "pars=np.loadtxt('LCDMmockdata_fim_snr.txt')\n",
    "dfpars=pd.DataFrame(pars, columns = ['mass_1', 'mass_2', 'a_1', 'a_2', 'tilt_1', 'tilt_2',\n",
    "                     'phi_12', 'phi_jl', 'luminosity_distance', 'theta_jn', 'psi',\n",
    "                     'phase', 'geocent_time', 'ra', 'dec','errm1','errm2','errDL','errl',\n",
    "                     'match_filter_SNR','optimal_SNR','ratioer/t'])\n",
    "#choose the snr larger 8 events\n",
    "snrp=dfpars['optimal_SNR']>8\n",
    "dfparsnrp=(dfpars[snrp]).reset_index(drop=True)\n",
    "resamppar=(dfparsnrp.sample(choiceN)).reset_index(drop=True)\n",
    "resampdata=resamppar\n",
    "#####################################################################\n",
    "deltadl=30 #############################step for DL \n",
    "errm1=resampdata['errm1']#####use err m1 from fisher matrix \n",
    "errm2=resampdata['errm2']#####use err m2 from fisher matrix \n",
    "errDL=resampdata['errDL']#####use err DL from fisher matrix \n",
    "max_samples=kk\n",
    "maxsamp=max_samples\n",
    "sampdl = resampdata['luminosity_distance']\n",
    "sampz=getz(sampdl,70,0.3)\n",
    "sampm1z=resampdata['mass_1']\n",
    "sampm2z=resampdata['mass_2']\n",
    "sampq=sampm2z/sampm1z\n",
    "choice_Nevents=choiceN\n",
    "Nevents=(choice_Nevents)\n",
    "lambdadl=np.zeros((choiceN,max_samples))\n",
    "sigmadl=np.zeros((choiceN,max_samples))\n",
    "lambdam1=np.zeros((choiceN,max_samples))\n",
    "sigmam1=np.zeros((choiceN,max_samples))\n",
    "lambdam2=np.zeros((choiceN,max_samples))\n",
    "sigmam2=np.zeros((choiceN,max_samples))\n",
    "#######################################################################################\n",
    "#theta=N(0,sigma_theta)+theta_True\n",
    "newsampDL=np.zeros(choiceN)\n",
    "newsampm1=np.zeros(choiceN)\n",
    "newsampm2=np.zeros(choiceN)\n",
    "newsampDL=np.array(sampdl)+np.random.normal(0,np.array(errDL))\n",
    "newsampm1=np.array(sampm1z)+np.random.normal(0,np.array(errm1))\n",
    "newsampm2=np.array(sampm2z)+np.random.normal(0,np.array(errm2))\n",
    "normmaxDL=max(newsampDL)+max(errDL)\n",
    "#######################################################################################\n",
    "#Gaussian PDF for DL, N([theta_Ture+N(0,sigma_fim^2)],sigma_fim)\n",
    "results1=list()\n",
    "for i in range(len(sampdl)):\n",
    "    data1=newsampDL[i]\n",
    "    errg=errDL[i]\n",
    "    lambdadl[i,:]=np.repeat(data1,maxsamp)\n",
    "    sigmadl[i,:]=np.repeat(data1*errg,maxsamp)\n",
    "    likelihood = SimpleGaussianLikelihood1s(data1)\n",
    "    priors = dict(mu1=bilby.core.prior.Uniform(1, 31300, 'mu1'),sigma1=errg)            \n",
    "    result1 = bilby.run_sampler(\n",
    "                   likelihood=likelihood, priors=priors, sampler='nestle', nlive=orlive,\n",
    "                   outdir=outdir, verbose=False,label='DLposterior_{}'.format(i),save=False)\n",
    "    results1.append(result1)\n",
    "samples1= [result1.posterior for result1 in results1]\n",
    "evidences1 = [result1.log_evidence for result1 in results1]\n",
    "########################################################\n",
    "results2=list()\n",
    "for i in range(len(sampm1z)):\n",
    "    data2=newsampm1[i]\n",
    "    errg=errm1[i]\n",
    "    lambdam1[i,:]=np.repeat(data2,maxsamp)\n",
    "    sigmam1[i,:]=np.repeat(data2*errg,maxsamp)\n",
    "    likelihood = SimpleGaussianLikelihood2s(data2)\n",
    "    priors = dict(mu2=bilby.core.prior.Uniform(7, 160, 'mu2'),sigma2=errg)            \n",
    "    result2 = bilby.run_sampler(\n",
    "                   likelihood=likelihood, priors=priors, sampler='nestle', nlive=orlive,\n",
    "                   outdir=outdir, verbose=False,label='m1posterior_{}'.format(i),save=False)\n",
    "    results2.append(result2)\n",
    "samples2= [result2.posterior for result2 in results2]\n",
    "evidences2 = [result2.log_evidence for result2 in results2]\n",
    "#########################################################\n",
    "results3=list()\n",
    "for i in range(len(sampm2z)):\n",
    "    data3=newsampm2[i]\n",
    "    errg=errm2[i]\n",
    "    lambdam2[i,:]=np.repeat(data3,maxsamp)\n",
    "    sigmam2[i,:]=np.repeat(data3*errg,maxsamp)\n",
    "    likelihood = SimpleGaussianLikelihood3s(data3)\n",
    "    priors = dict(mu3=bilby.core.prior.Uniform(6.8, 124.8, 'mu3'),sigma3=errg)            \n",
    "    result3 = bilby.run_sampler(\n",
    "                   likelihood=likelihood, priors=priors, sampler='nestle', nlive=orlive,\n",
    "                   outdir=outdir, verbose=False,label='m2posterior_{}'.format(i),save=False)\n",
    "    results3.append(result3)\n",
    "samples3= [result3.posterior for result3 in results3]\n",
    "evidences3 = [result3.log_evidence for result3 in results3]\n",
    "dfsampre=list()\n",
    "for i in range(len(sampdl)):\n",
    "    dfsamp1=((samples1[i]).sample(n=maxsamp)).reset_index(drop=True)\n",
    "    dfsamp2=((samples2[i]).sample(n=maxsamp)).reset_index(drop=True)\n",
    "    dfsamp3=((samples3[i]).sample(n=maxsamp)).reset_index(drop=True)\n",
    "    dfsamp12=pd.concat([dfsamp1,dfsamp2,dfsamp3],axis=1)\n",
    "    dfsamp12.columns=['mu1','sigma1','log_likelihood1','log_prior1','mu2','sigma2','log_likelihood2','log_prior2','mu3','sigma3','log_likelihood3','log_prior3']\n",
    "    dfsampre.append(dfsamp12)\n",
    "#combine the posterior DL m1 m2, calculated the total evidence\n",
    "evidences=np.array(evidences1)+np.array(evidences2)+np.array(evidences3)\n",
    "#####################################################################\n",
    "#hyper prior \\pi(DL,m1,m2|H0,omm,M_LCDM) in source frame\n",
    "def normPDL(DL,H0,omm):\n",
    "    ss=np.trapz(PDL(np.arange(0,(normmaxDL+200),100),H0,omm),np.arange(0,(normmaxDL+200),100))\n",
    "    return PDL(DL,H0,omm)/ss \n",
    "def hyper_prior(data,H0,omm):\n",
    "    return normPDL(data['mu1'],H0,omm)*normPm1(data['mu2']/(np.array((getz(data['mu1'],H0,omm)))+1))\\\n",
    "           *normPm2((data['mu3']/(np.array((getz(data['mu1'],H0,omm))))),(data['mu2']/(np.array((getz(data['mu1'],H0,omm))))))\n",
    "#defalt prior \\pi(DL,m1,m2|phi)\n",
    "def run_prior(data):\n",
    "    return 1\n",
    "hp_likelihood = HyperparameterLikelihood(\n",
    "    posteriors=dfsampre, hyper_prior=hyper_prior,\n",
    "    sampling_prior=run_prior, log_evidences=evidences, max_samples=kk)\n",
    "\n",
    "hp_priors = dict(H0=Uniform(30,110, 'H0', '$H0$')\n",
    "                 ,omm=Uniform(0.01,0.7, 'omm', '$\\Omega_m$'))\n",
    "result = run_sampler(\n",
    "    likelihood=hp_likelihood, priors=hp_priors, sampler='dynesty', nlive=2000,\n",
    "    use_ratio=False, outdir=outdir, label='LCDM20190529N200hyper_parameter',\n",
    "    verbose=True, clean=True)\n",
    "result.plot_corner(truth=dict(H0=70,omm=0.3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
